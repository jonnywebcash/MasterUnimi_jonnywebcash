{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dde418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import (mutual_info_score, normalized_mutual_info_score,adjusted_mutual_info_score)\n",
    "from sklearn.metrics import (homogeneity_score,completeness_score,v_measure_score)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.close('all') \n",
    "\n",
    "# Generazione della heatmap valutando la correlazione delle singole features con le singole specie\n",
    "def feature_vs_class_heatmap(df,species_dict):\n",
    "    df_tmp=df.copy()\n",
    "    df_tmp['type']=df_tmp['type'].map(species_dict)    \n",
    "    # One-hot encoding\n",
    "    df_tmp=pd.get_dummies(df_tmp,columns=[\"type\"])\n",
    "    # Creazione matrice correlazione\n",
    "    corr_matrix = df_tmp.corr().abs()\n",
    "    # grafico della heatmap\n",
    "    sns.heatmap(corr_matrix)\n",
    "    \n",
    "    # Selezione del tringolo superiore della matrice di correlazione\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    # Estraiamo tutte le combinazioni di feature e le filtriamo per avere solo le correlazioni tra i type e le feature\n",
    "    s = upper.unstack()\n",
    "    added_dummy_cols = [item for item in list(df_tmp.columns.values) if (item not in(df.columns.values))]\n",
    "    so=s[s.index.isin(added_dummy_cols, level=0)]\n",
    "    so=so[~so.index.isin(added_dummy_cols, level=1)]\n",
    "    so = so.sort_values(kind=\"quicksort\",ascending=False, na_position='last')\n",
    "    so.columns =['corr']\n",
    "    so.index=so.index.set_names(['type','feature'])\n",
    "    so=so.reset_index()\n",
    "    so.columns=['type','feature','corr']\n",
    "    \n",
    "    plt.figure()\n",
    "    cmap =plt.colormaps['jet']\n",
    "    \n",
    "    cnt=1\n",
    "    for cluster in added_dummy_cols:\n",
    "        sub_df=so[so[\"type\"]==cluster]\n",
    "        sub_df=sub_df.sort_values('feature')\n",
    "        \n",
    "        plt.subplot(2, 4,cnt)\n",
    "        plt.title(cluster)\n",
    "        plt.bar(sub_df['feature'], sub_df['corr'], align='center',color=cmap(sub_df['corr']))     \n",
    "        #plt.xlabel(sub_df['feature'].values.tolist())\n",
    "        plt.xticks(rotation = 60)\n",
    "        plt.ylabel(\"corr\")    \n",
    "        plt.ylim(ymin = 0,ymax = 1)\n",
    "        plt.grid(True)\n",
    "        #plt.tight_layout()\n",
    "        cnt=cnt+1\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Barplot della distribuzione delle varie classi all'interno del dataset\n",
    "def class_distributuion_barplot(df,species_dict):\n",
    "    sub_df=df.groupby([\"type\"])[\"type\"].count().reset_index(name=\"count\").copy()\n",
    "    sub_df['perc'] = sub_df['count'].groupby(sub_df['type']).transform(lambda x: x/df.shape[0])\n",
    "    sub_df['type']=sub_df['type'].map(species_dict)\n",
    "    sns.set() \n",
    "    fig, axes = plt.subplots(2, 1)\n",
    "    fig.suptitle('Dataset composition')\n",
    "    sns.barplot(x =\"type\", y = 'perc', data = sub_df, hue = \"type\",ax=axes[0])    \n",
    "    sns.barplot(x =\"type\", y = 'count', data = sub_df, hue = \"type\",ax=axes[1])\n",
    "\n",
    "# Barplot della distribuzione percentuale all'interno di ogni classe dei valori delle singole features \n",
    "def barplot_class_feature_distribution(df,species_dict):\n",
    "   feature_name=['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed']\n",
    "   cnt=0\n",
    "   sns.set() \n",
    "   fig, axes = plt.subplots(2, 4, sharey=True)\n",
    "   fig.suptitle('Class features composition')\n",
    "   for feature in feature_name:\n",
    "       sub_df=df.groupby([\"type\", feature])[feature].count().reset_index(name=\"count\").copy()\n",
    "       sub_df['perc'] = sub_df['count'].groupby(sub_df['type']).transform(lambda x: x/x.sum())\n",
    "       sub_df['type']=sub_df['type'].map(species_dict) \n",
    "       sns.barplot(x =\"type\", y = 'perc', data = sub_df, hue = feature,ax=axes[cnt//4,cnt%4])\n",
    "       axes[cnt//4,cnt%4].set_xticklabels(axes[cnt//4,cnt%4].get_xticklabels(), rotation=45)\n",
    "       # axes[cnt//4,cnt%4].set_title(feature)       \n",
    "       cnt=cnt+1\n",
    "    \n",
    "   feature_name=['backbone','breathes','venomous','fins','legs','tail','domestic','catsize']\n",
    "   cnt=0\n",
    "   fig, axes = plt.subplots(2, 4, sharey=True)\n",
    "   fig.suptitle('Class features composition')\n",
    "   for feature in feature_name:\n",
    "        sub_df=df.groupby([\"type\", feature])[feature].count().reset_index(name=\"count\").copy()\n",
    "        sub_df['perc'] = sub_df['count'].groupby(sub_df['type']).transform(lambda x: x/x.sum())\n",
    "        sub_df['type']=sub_df['type'].map(species_dict) \n",
    "        sns.barplot(x =\"type\", y = 'perc', data = sub_df, hue = feature,ax=axes[cnt//4,cnt%4])\n",
    "        axes[cnt//4,cnt%4].set_xticklabels(axes[cnt//4,cnt%4].get_xticklabels(), rotation=45)        \n",
    "        # axes[cnt//4,cnt%4].set_title(feature)        \n",
    "        cnt=cnt+1\n",
    "        \n",
    "# Assegna una label al cluster in base alla classe di maggioranza        \n",
    "def majority_voting_label(df):\n",
    "    \n",
    "    predict_major=df['type'].groupby(df['predict']).value_counts().groupby(level=[0], group_keys=False).head(1).to_frame('counts').reset_index()\n",
    "    predict_major=df.set_index('predict').to_dict()['type']\n",
    "    df['predict_label']=df['predict'].map(predict_major)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def replace_predict_with_major(df):\n",
    "    # Valutazione predict\n",
    "    #predict_major={}\n",
    "    # for result_predict in (df['predict'].unique()):\n",
    "    #     sub_df=df[df[\"predict\"]==result_predict]\n",
    "    #     major_species=sub_df['type'].value_counts().idxmax()\n",
    "    #     predict_major[int(result_predict)]=major_species\n",
    "    predict_major=df['type'].groupby(df['predict']).value_counts().groupby(level=[0], group_keys=False).head(1).to_frame('counts').reset_index()\n",
    "    predict_major=df.set_index('predict').to_dict()['type']\n",
    "    # for chiave in predict_major.keys():\n",
    "    #     df['predict'] = df['predict'].replace([int(chiave)], species_dict[predict_major[chiave]])\n",
    "    df['predict']=df['predict'].map(predict_major)\n",
    "    return(df)\n",
    "\n",
    " \n",
    "def replace_species(df,species_dict):\n",
    "    df['predict_label']=df['predict_label'].map(species_dict)  \n",
    "    df['type']=df['type'].map(species_dict)    \n",
    "    return(df)\n",
    "\n",
    "def confusion_matrix_plot(df):\n",
    "    cm = confusion_matrix(df['type'],df['predict_label'])\n",
    "    sns.set() \n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.xlabel(\"Predicted Class by majority voting\")\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.title('Confusion matrix:'+df['model_name'][0])\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot_result(df):\n",
    "    df['type'] = df['type'].apply(lambda x: x + np.random.randint(-40,40)/100)\n",
    "    df['predict_label'] = df['predict_label'].apply(lambda x: x + np.random.randint(-40,40)/100)\n",
    "    groups = df.groupby('predict')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    circle0 = plt.Circle((0,0), 0.5,  fill=False)\n",
    "    circle1 = plt.Circle((1,1), 0.5,  fill=False)\n",
    "    circle2 = plt.Circle((2,2), 0.5,  fill=False)\n",
    "    circle3 = plt.Circle((3,3), 0.5,  fill=False)\n",
    "    circle4 = plt.Circle((4,4), 0.5,  fill=False)\n",
    "    circle5 = plt.Circle((5,5), 0.5,  fill=False)\n",
    "    circle6 = plt.Circle((6,6), 0.5,  fill=False)\n",
    "\n",
    "    ax.set_xticks(np.arange(-1, 7, 1))\n",
    "    ax.set_yticks(np.arange(-1, 7, 1))\n",
    "    #plt.scatter(df['type'], df['predict_label'], c=df['predict'], cmap='viridis')\n",
    "    for cluster, group in groups:\n",
    "        plt.plot(group.type, group.predict_label, marker='o', linestyle='', markersize=8, label=cluster)\n",
    "    \n",
    "    plt.xlabel('type')\n",
    "    plt.ylabel('majority voting label')\n",
    "    ax.add_patch(circle0)\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "    ax.add_patch(circle3)\n",
    "    ax.add_patch(circle4)\n",
    "    ax.add_patch(circle5)\n",
    "    ax.add_patch(circle6)\n",
    "    plt.grid()\n",
    "    plt.title(df['model_name'][0])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return(df)\n",
    "\n",
    "\n",
    "\n",
    "def barplot_class_feature_distribution(df,species_dict):\n",
    "   feature_name=['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed']\n",
    "   cnt=0\n",
    "   sns.set() \n",
    "   fig, axes = plt.subplots(2, 4, sharey=True)\n",
    "   fig.suptitle('Class features composition')\n",
    "   for feature in feature_name:\n",
    "       sub_df=df.groupby([\"type\", feature])[feature].count().reset_index(name=\"count\").copy()\n",
    "       sub_df['perc'] = sub_df['count'].groupby(sub_df['type']).transform(lambda x: x/x.sum())\n",
    "       sub_df['type']=sub_df['type'].map(species_dict) \n",
    "       sns.barplot(x =\"type\", y = 'perc', data = sub_df, hue = feature,ax=axes[cnt//4,cnt%4])\n",
    "       axes[cnt//4,cnt%4].set_xticklabels(axes[cnt//4,cnt%4].get_xticklabels(), rotation=45)\n",
    "       # axes[cnt//4,cnt%4].set_title(feature)       \n",
    "       cnt=cnt+1\n",
    "    \n",
    "   feature_name=['backbone','breathes','venomous','fins','legs','tail','domestic','catsize']\n",
    "   cnt=0\n",
    "   fig, axes = plt.subplots(2, 4, sharey=True)\n",
    "   fig.suptitle('Class features composition')\n",
    "   for feature in feature_name:\n",
    "        sub_df=df.groupby([\"type\", feature])[feature].count().reset_index(name=\"count\").copy()\n",
    "        sub_df['perc'] = sub_df['count'].groupby(sub_df['type']).transform(lambda x: x/x.sum())\n",
    "        sub_df['type']=sub_df['type'].map(species_dict) \n",
    "        sns.barplot(x =\"type\", y = 'perc', data = sub_df, hue = feature,ax=axes[cnt//4,cnt%4])\n",
    "        axes[cnt//4,cnt%4].set_xticklabels(axes[cnt//4,cnt%4].get_xticklabels(), rotation=45)        \n",
    "        # axes[cnt//4,cnt%4].set_title(feature)        \n",
    "        cnt=cnt+1\n",
    "\n",
    "def barplot_class_feature_percentage(df,species_dict):\n",
    "    feature_name=['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize','type']\n",
    "    for result_predict in (df['predict'].unique()):\n",
    "        \n",
    "        sub_df=df[df[\"predict\"]==result_predict].copy() \n",
    "        cnt=1\n",
    "        plt.figure()\n",
    "        for feature in feature_name:\n",
    "            # get colum value distribution\n",
    "            a = (sub_df[feature].value_counts(normalize=True) \n",
    "                        .mul(100)\n",
    "                        .rename_axis(feature)\n",
    "                        .reset_index(name='percentage'))\n",
    "            # creating the bar plot\n",
    "            \n",
    "            plt.subplot(3, 6,cnt)\n",
    "            #plt.title(feature)\n",
    "            plt.bar(a[feature].values.tolist(), a['percentage'], align='center', color ='b')\n",
    "         \n",
    "            plt.xlabel(feature)\n",
    "            plt.ylabel(\"Percentage [%]\")    \n",
    "            #ax[cnt].plt.show()\n",
    "            cnt=cnt+1\n",
    "        # Show the plots\n",
    "        sub_df['predict']=sub_df['predict'].map(species_dict) \n",
    "        plt.suptitle(\"predict:\"+sub_df['predict'].unique())\n",
    "        plt.show()\n",
    "\n",
    "def barplot_class_feature_comparison(df,species_dict, major_label_voting):\n",
    "   if major_label_voting==1:\n",
    "        predict_major=df['type'].groupby(df['predict']).value_counts().groupby(level=[0], group_keys=False).head(1).to_frame('counts').reset_index()\n",
    "        predict_major=df.set_index('predict').to_dict()['type']\n",
    "        for k in predict_major:\n",
    "            predict_major[k]=str(k)+'_'+species_dict[predict_major[k]]\n",
    "        \n",
    "   feature_name=['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed']\n",
    "   cnt=0\n",
    "   sns.set() \n",
    "   fig, axes = plt.subplots(2, 4, sharey=True)\n",
    "   fig.suptitle('Class features composition')\n",
    "   for feature in feature_name:\n",
    "       sub_df=df.groupby([\"predict\", feature])[feature].count().reset_index(name=\"count\")\n",
    "       sub_df['perc'] = sub_df['count'].groupby(sub_df['predict']).transform(lambda x: x/x.sum())\n",
    "       if major_label_voting==1:           \n",
    "           sub_df['predict']=sub_df['predict'].map(predict_major)\n",
    "       sns.barplot(x =\"predict\", y = 'perc', data = sub_df, hue = feature,ax=axes[cnt//4,cnt%4])\n",
    "       axes[cnt//4,cnt%4].set_xticklabels(axes[cnt//4,cnt%4].get_xticklabels(), rotation=45)\n",
    "       # axes[cnt//4,cnt%4].set_title(feature)       \n",
    "       cnt=cnt+1\n",
    "    \n",
    "   feature_name=['backbone','breathes','venomous','fins','legs','tail','domestic','catsize']\n",
    "   cnt=0\n",
    "   fig, axes = plt.subplots(2, 4, sharey=True)\n",
    "   fig.suptitle('Class features composition')\n",
    "   for feature in feature_name:\n",
    "        sub_df=df.groupby([\"predict\", feature])[feature].count().reset_index(name=\"count\")\n",
    "        sub_df['perc'] = sub_df['count'].groupby(sub_df['predict']).transform(lambda x: x/x.sum())\n",
    "        if major_label_voting==1:           \n",
    "            sub_df['predict']=sub_df['predict'].map(predict_major)\n",
    "        sns.barplot(x =\"predict\", y = 'perc', data = sub_df, hue = feature,ax=axes[cnt//4,cnt%4])\n",
    "        axes[cnt//4,cnt%4].set_xticklabels(axes[cnt//4,cnt%4].get_xticklabels(), rotation=45)        \n",
    "        # axes[cnt//4,cnt%4].set_title(feature)        \n",
    "        cnt=cnt+1\n",
    "\n",
    "def classification_percentage_performance(df,species_dict):\n",
    "    df=replace_predict_with_major(df).copy()    \n",
    "    sub_df=df.groupby([\"type\", \"predict_label\"])[\"predict\"].count().reset_index(name=\"count\")\n",
    "    sub_df['perc'] = sub_df['count'].groupby(sub_df['type']).transform(lambda x: x/x.sum())\n",
    "    if   type(sub_df['predict'][0]) == int or type(sub_df['predict'][0]) == float:\n",
    "        sub_df['predict']=sub_df['predict'].map(species_dict)\n",
    "    if   type(sub_df['type'][0]) == int or type(sub_df['type'][0]) == float:\n",
    "        sub_df['type']=sub_df['type'].map(species_dict)\n",
    "    sns.set() \n",
    "    fig, axes = plt.subplots(2, 1)\n",
    "    fig.suptitle('Distribution of classified classes')\n",
    "    sns.barplot(x =\"type\", y = 'perc', data = sub_df, hue = \"predict\",ax=axes[0])    \n",
    "    sns.barplot(x =\"type\", y = 'count', data = sub_df, hue = \"predict\",ax=axes[1])\n",
    "    \n",
    "\n",
    "def similarity_index(df):\n",
    "    # df=df_tmp\n",
    "    predict_major=df['type'].groupby(df['predict']).value_counts().groupby(level=[0], group_keys=False).head(1).to_frame('counts').reset_index()\n",
    "    predict_major=df.set_index('predict').to_dict()['type']\n",
    "    if   type(df['predict'][0]) == int or type(df['predict'][0]) == float:\n",
    "        df['predict']=df['predict'].map(predict_major)\n",
    "    \n",
    "\n",
    "    df=replace_predict_with_major(df)\n",
    "    similarity_dict={}\n",
    "    for real_type in (df['type'].unique()):\n",
    "        sub_df=df[df[\"type\"]==real_type]\n",
    "        match=sub_df[sub_df[\"predict\"]==real_type]\n",
    "        if match.shape[0]>0:\n",
    "            similarity_dict[real_type]=match.shape[0]/sub_df.shape[0]*100\n",
    "        else:\n",
    "            similarity_dict[real_type]=0\n",
    "    myKeys = list(similarity_dict.keys())\n",
    "    myKeys.sort()\n",
    "    sorted_dict = {i: similarity_dict[i] for i in myKeys}\n",
    "    similarity_dict=sorted_dict\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    plt.bar(range(len(similarity_dict)), list(similarity_dict.values()), tick_label=list(similarity_dict.keys()))\n",
    "    plt.xlabel('type')\n",
    "    plt.ylabel('Similarity inside the group')\n",
    "    plt.show()\n",
    "    return(similarity_dict)\n",
    "\n",
    "def dissimilarity_index(df):\n",
    "    df_tmp = pd.DataFrame(columns = list(df.columns.values)).copy()\n",
    "    # Valutazione predict\n",
    "    for result_predict in (df['predict'].unique()):\n",
    "        sub_df=df[df[\"predict\"]==result_predict]\n",
    "        major_species=sub_df['type'].value_counts().idxmax()\n",
    "        sub_df['predict label'] =major_species\n",
    "        df_tmp=pd.concat([df_tmp, sub_df], axis=0)\n",
    "\n",
    "    df=df_tmp\n",
    "    dissimilarity_dict={}\n",
    "    for real_type in (df['type'].unique()):\n",
    "        sub_df=df[df[\"type\"]==real_type]\n",
    "        match=sub_df[sub_df[\"predict label\"]==real_type]\n",
    "        dissimilarity_dict[real_type]=((sub_df.shape[0]-match.shape[0])/sub_df.shape[0])*100\n",
    "    myKeys = list(dissimilarity_dict.keys())\n",
    "    myKeys.sort()\n",
    "    sorted_dict = {i: dissimilarity_dict[i] for i in myKeys}\n",
    "    dissimilarity_dict=sorted_dict\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca()\n",
    "    plt.bar(range(len(dissimilarity_dict)), list(dissimilarity_dict.values()), tick_label=list(dissimilarity_dict.keys()))\n",
    "    plt.xlabel('type')\n",
    "    plt.ylabel('Dissimilarity inside the group')\n",
    "    plt.show()\n",
    "    return(dissimilarity_dict)\n",
    "\n",
    "def rand_index(df):\n",
    "    ri = rand_score(df['type'], df['predict'])\n",
    "    return(ri)\n",
    "\n",
    "def adjusted_rand_index(df):\n",
    "    ari = adjusted_rand_score(df['type'], df['predict'])\n",
    "    return(ari)\n",
    "\n",
    "def mutual_information_index(df):\n",
    "    MI = mutual_info_score(df['type'], df['predict'])\n",
    "    NMI = normalized_mutual_info_score(df['type'], df['predict'])\n",
    "    return(MI,NMI)\n",
    "\n",
    "def v_measure_index(df):\n",
    "    HS = homogeneity_score(df['type'], df['predict'])\n",
    "    CS = completeness_score(df['type'], df['predict'])\n",
    "    V = v_measure_score(df['type'], df['predict'], beta=1.0)\n",
    "    return(HS,CS,V)\n",
    "\n",
    "def silhouette_score_index(df):\n",
    "    ss = silhouette_score(df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']], df['predict'])\n",
    "    ss=(ss+1)/2\n",
    "    return(ss)\n",
    "\n",
    "def model_performance_evaluation(df_full,df,model_comparison):\n",
    "    \n",
    "     # Similarity index\n",
    "    #similarity_score=similarity_index(df)\n",
    "    # Dissimilarità index\n",
    "    #dissimilarity_score=dissimilarity_index(df)\n",
    "    \n",
    "    #Rand Index\n",
    "    # Misura la somiglianza tra le assegnazioni del cluster effettuando confronti a coppie. Un punteggio più alto indica una somiglianza maggiore.\n",
    "    # RI = (numero di previsioni corrette a coppie) / (numero totale di possibili coppie)\n",
    "    ri_score=rand_index(df)\n",
    "    \n",
    "    # Adjusted Rand Index\n",
    "    #L'indice RAND regolato è una metrica di valutazione che viene utilizzata per misurare la\n",
    "    # somiglianza tra due clustering considerando tutte le coppie di N_SAMPLE e calcolando le coppie\n",
    "    # di conteggio delle stesse o diversi cluster nel raggruppamento effettivo e previsto.\n",
    "    #ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)\n",
    "    # A score above 0.7 is considered to be a good match. \n",
    "    # ari_score=adjusted_rand_index(df)\n",
    "    \n",
    "    # Mutual Information (MI, NMI)\n",
    "    # Le informazioni reciproche (MI, NMI, AMI) misurano l'accordo tra le assegnazioni del cluster.\n",
    "    # Un punteggio più alto indica una somiglianza maggiore.\n",
    "    MI_score,NMI_score=mutual_information_index(df)\n",
    "    \n",
    "    # V-measure\n",
    "    # V-Measure misura la correttezza delle assegnazioni del cluster usando l'analisi dell'entropia condizionale.\n",
    "    # Un punteggio più alto indica una somiglianza maggiore\n",
    "    # Omogeneità: ogni cluster contiene solo membri di una singola classe (un po 'come \"precisione\")\n",
    "    # Completezza: tutti i membri di una determinata classe sono assegnati allo stesso cluster (un po 'come \"richiamo\")\n",
    "    HS_score,CS_score,V_score=v_measure_index(df)\n",
    "    \n",
    "    # Silhouette Score aka Silhouette Coefficient\n",
    "    # Silhouette score aka Silhouette Coefficient is an evaluation metric that results in the range of -1 to 1. A score near 1 signifies the best importance that the data point is very compact within the cluster to which it belongs and far away from the other clusters. The score near -1 signifies the least or worst importance of the data point. A score near 0 signifies overlapping clusters. \n",
    "    ss_score=silhouette_score_index(df_full)\n",
    "    \n",
    "    new_row=[[df['model_type'][0],df['model_name'][0],ri_score,MI_score,NMI_score,HS_score,CS_score,V_score,ss_score]]\n",
    "    \n",
    "    model_comparison= model_comparison.append(pd.DataFrame(new_row, columns=model_comparison.columns))\n",
    "    return(model_comparison)\n",
    "\n",
    "def AffinityM_prediction(df, k):\n",
    "    affinityM = AffinityPropagation(damping=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    affinityM.fit(features)\n",
    "    df['predict'] = affinityM.predict(features)\n",
    "    df['model_type'] = 'AffinityPropagation'\n",
    "    df['model_name'] = 'AffinityPropagation_'+str(k)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def agglomerativeClustering_prediction(df, k):\n",
    "    agglomerativeC = AgglomerativeClustering(n_clusters=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    df['predict'] = agglomerativeC.fit_predict(features)\n",
    "    df['model_type'] = 'AgglomerativeClustering'\n",
    "    df['model_name'] = 'AgglomerativeClustering_'+str(k)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "   \n",
    "def birch_prediction(df, k,th):\n",
    "    birchM = Birch(threshold=th, n_clusters=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    birchM.fit(features)\n",
    "    df['predict'] = birchM.predict(features)\n",
    "    df['model_type'] = 'birch'\n",
    "    df['model_name'] = 'birchMlustering_k:_'+str(k)+'_th_'+str(th)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def dbscan_prediction(df,eps_v,min_sam):\n",
    "    dbscan_model = DBSCAN( eps = eps_v, min_samples = min_sam)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    dbscan_model.fit(features)    \n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = dbscan_model.labels_\n",
    "    df['model_type'] = 'dbscan'\n",
    "    df['model_name'] = 'dbscan_eps_'+str(eps_v)+'_min_samples_'+str(min_sam)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def optics_m_prediction(df,eps_v,min_sam):\n",
    "    optics_m_model = OPTICS( eps = eps_v, min_samples = min_sam)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = optics_m_model.fit_predict(features)    \n",
    "    df['model_type'] = 'optics'\n",
    "    df['model_name'] = 'optics_m_eps_'+str(eps_v)+'_min_samples_'+str(min_sam)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def kmeans_prediction(df, k):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    kmeans.fit(features)\n",
    "    \n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = kmeans.predict(features)\n",
    "    df['model_type'] = 'kmeans'\n",
    "    df['model_name'] = 'kmeans_'+str(k)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def mb_kmeans_prediction(df, k):\n",
    "    mb_kmeans = MiniBatchKMeans(n_clusters=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    mb_kmeans.fit(features)\n",
    "    \n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = mb_kmeans.predict(features)\n",
    "    df['model_type'] = 'mb_kmeans'\n",
    "    df['model_name'] = 'mb_kmeans_'+str(k)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def mean_shift_prediction(df):\n",
    "    mean_shift = MeanShift()\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()\n",
    "    mean_shift.fit(features)\n",
    "    \n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = mean_shift.predict(features)\n",
    "    df['model_type'] = 'mean_shift'\n",
    "    df['model_name'] = 'mean_shift'\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def spectral_clustering_prediction(df,k):\n",
    "    spectral_clustering = SpectralClustering(n_clusters=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()    \n",
    "    \n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = spectral_clustering.fit_predict(features)\n",
    "    df['model_type'] = 'spectral_clustering'\n",
    "    df['model_name'] = 'spectral_clustering'+str(k)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def gaussian_mixture_prediction(df,k):\n",
    "    gaussian_mixture =GaussianMixture(n_components=k)\n",
    "    features=df[['hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize']].copy()    \n",
    "    gaussian_mixture.fit(features)\n",
    "    # Assegna le etichette dei cluster a ogni oggetto del dataset\n",
    "    df['predict'] = gaussian_mixture.predict(features)\n",
    "    df['model_type'] = 'gaussian_mixture'\n",
    "    df['model_name'] = 'gaussian_mixture'+str(k)\n",
    "    majority_voting_label(df)\n",
    "    return(df)\n",
    "\n",
    "def get_best_models(model_comparison):\n",
    "    df=model_comparison.copy()\n",
    "    df['resume_index']=df[['ri','NMI','V','siluetteN']].mean(axis=1)\n",
    "    df.groupby('model_type')['resume_index'].max()\n",
    "    idx_best = df.groupby('model_type')['resume_index'].transform(max) == df['resume_index']\n",
    "    best_models=df[idx_best]\n",
    "    return(best_models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
